[["index.html", "机器学习（2022 秋，80250993） Chapter 1 前言 1.1 课程大纲 1.2 课程参考书", " 机器学习（2022 秋，80250993） Jim Zhang 2022-09-23 Chapter 1 前言 本系列讲义为 Jim 根据自己的理解，对于清华大学自动化系教授、ISCB Fellow、生命学院和医学院兼职教授、R 语言DEGseq库作者张学工老师于 2022 年秋季开设的《Machine Learning》课程讲义进行的重新诠释。 1.1 课程大纲 Week Date Course content 1 09/15 Introdution, Pattern Classifiers and Their Assessment 2 09/22 Linear Learning Machines (Linear Classifiers, Linear Regression, MSE/ADALINE, Logistic Regression, Fisher’s Linear Discriminant, Perceptron) 1.2 课程参考书 张学工、汪小我，《模式识别（第四版）：模式识别与机器学习》，清华大学出版社，2021.8. R.O. Duda, P.E. Hart, D.G. Stork, Pattern Classification (2nd edition), John Wiley &amp; Sons, Inc, 2001. S. Raschka &amp; V. Mirjalili, Python Machine Learning (2nd edition), Birmingham, Packt Publishing, 2017. Y. S. Abu-Mostafa, M. Magdon-Ismail, H-T. Lin, Learning from Data, AMLbook.com, 2012. Christopher M. Bishop, Pattern Recognition and Machine Learning, New York, Springer, 2006. T. Hastie, R. Tibshirani, J. Friedman, The Elements of Statistical Learning (2nd edition), New York, Springer, 2016. S. Shalev-Shwartz &amp; S. Ben-David, Understanding Machine Learning: From Theory to Algorithms, Cambridge University Press, 2014. I. Goodfellow, Y. Bengio, A. Courville, Deep Learning, MIT Press, 2016. "],["错误.html", "Chapter 2 错误", " Chapter 2 错误 "],["线性学习机.html", "Chapter 3 线性学习机 3.1 线性判别分析 —— Fisher 的线性判别法", " Chapter 3 线性学习机 3.1 线性判别分析 —— Fisher 的线性判别法 先讨论一些线性可分的二分类问题： Figure 3.1: 线性可分的二分类问题 这些点显然线性可分。我们知道，一个线性判别器的形式如下： \\[ f(\\boldsymbol{x})=\\boldsymbol{w}^T\\boldsymbol{x}+w_0 \\] 其中，\\(y=f(\\boldsymbol{x})\\in\\mathbb{R}, \\boldsymbol{w}, \\boldsymbol{x}\\in\\mathbb{R}^n, w_0\\in\\mathbb{R}\\)。 决策边界为：\\(f(\\boldsymbol{x})=0\\)，即： \\[ \\begin{cases} f(\\boldsymbol{x})&gt;0\\rightarrow\\boldsymbol{x}\\in\\omega_1 \\\\ f(\\boldsymbol{x})&lt;0\\rightarrow\\boldsymbol{x}\\in\\omega_2 \\end{cases} \\] 或者使用 \\(y=\\text{sgn}(f(\\boldsymbol{x}))=\\text{sgn}(\\boldsymbol{w}^T\\boldsymbol{x}+w_0)\\) 会更方便一点： \\[ y = \\text{sgn}(f(\\boldsymbol{x})) = \\begin{cases} 1&amp;\\rightarrow\\boldsymbol{x}\\in\\omega_1 \\\\ -1&amp;\\rightarrow\\boldsymbol{x}\\in\\omega_2 \\end{cases} \\] 那问题来了，在这个例子中线性可分会存在一定的操作空间（改变 \\(\\boldsymbol{w}^T\\) 和 \\(w_0\\)，即调整方向和平移，这个定义我们之后再说），那么最好的判别器是什么呢？Fisher（文献）给出了一种方法：最大化类内散度和类间散度的比值。 首先定义了这样一个映射： \\[ \\mathcal{X}\\rightarrow\\mathcal{Y}:\\quad y_i=\\boldsymbol{w}^T\\boldsymbol{x}_i \\] 对 \\(\\boldsymbol{x}\\) 来说，定义类内散度： \\[ \\boldsymbol{S}_i=\\sum_{\\boldsymbol{x}_j\\in \\mathcal{X}_i}\\Vert\\boldsymbol{x}_j-\\boldsymbol{m}_i\\Vert^2_2,\\quad i=1,2 \\] 其中 \\(\\boldsymbol{m}_i\\) 是类 \\(\\mathcal{X}_i\\) 的均值向量，\\(S_i\\) 表示类 \\(\\mathcal{X}_i\\) 的类内散度。 总类内散度： \\[ \\boldsymbol{S}_w=\\sum S_i,\\quad i=1,2 \\] 类间散度： \\[ \\boldsymbol{S}_b = \\Vert\\boldsymbol{m}_1-\\boldsymbol{m}_2\\Vert^2_2 \\] 而对于 \\(y=f(\\boldsymbol{x})\\) 来说，均值是： \\[ \\tilde{m}_i=\\frac{1}{N_i}\\sum_{y_j\\in\\mathcal{Y}_i} y_j,\\quad i=1,2 \\] 其中 \\(N_i\\) 是类 \\(\\mathcal{Y}_i\\) 的样本数，\\(\\tilde{m}_i\\) 是类 \\(\\mathcal{Y}_i\\) 的均值。 类内散度： \\[ S_i=\\sum_{y_j\\in\\mathcal{Y}_i}(y_j-\\tilde{m}_i)^2,\\quad i=1,2 \\] 总类内散度： \\[ \\tilde{S}_w=\\sum\\tilde{S}_i,\\quad i=1,2 \\] 类间散度： \\[ \\tilde{S}_b=(\\tilde{m}_1-\\tilde{m}_2)^2 \\] 那么，Fisher 的准则就是： \\[ \\max_{\\boldsymbol{w}} J_{F}(\\boldsymbol{w})=\\frac{\\tilde{S}_b}{\\tilde{S}_w}=\\frac{\\boldsymbol{w}^T\\boldsymbol{S}_b\\boldsymbol{w}}{\\boldsymbol{w}^T\\boldsymbol{S}_w\\boldsymbol{w}} \\] 然后我们要解出 \\(\\boldsymbol{w}^\\ast=\\underset{\\boldsymbol{w}}{\\operatorname{arg\\,max}}\\,J_F(\\boldsymbol{w})\\)，怎么办呢？一种办法是假设分母是常数，使用拉格朗日乘子法，即： \\[ \\max \\boldsymbol{w}^T\\boldsymbol{S}_b\\boldsymbol{w} \\quad \\text{s.t.} \\quad \\boldsymbol{w}^T\\boldsymbol{S}_w\\boldsymbol{w}=c \\] "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
